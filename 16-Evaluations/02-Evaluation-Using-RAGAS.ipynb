{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAGAS 를 활용한 평가\n",
    "\n",
    "**참고**\n",
    "- RAGAS: https://docs.ragas.io/en/latest/getstarted/evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH16-Evaluations\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH16-Evaluations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 저장한 CSV 파일로부터 로드\n",
    "\n",
    "- `data/ragas_synthetic_dataset.csv` 파일을 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the key considerations regarding AI f...</td>\n",
       "      <td>['∙ 3개국은 기반모델 전반에 대한 규제가 기술 중립적이고 위험 기반의 AI 규제...</td>\n",
       "      <td>Key considerations regarding AI foundation mod...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the key features and improvements of ...</td>\n",
       "      <td>['1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n알리바바 클라...</td>\n",
       "      <td>The key features and improvements of the LLM '...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the purpose of the AAAI Conference?</td>\n",
       "      <td>['Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 미국 소비자기술 협회(C...</td>\n",
       "      <td>The purpose of the AAAI Conference is to advan...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What role does content moderation play in the ...</td>\n",
       "      <td>['£유튜브, 특정인을 모방한 AI 생성 콘텐츠에 대한 삭제 요청에도 대응 계획\\n...</td>\n",
       "      <td>Content moderation plays a crucial role in AI ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What FTC concerns exist on AI comp. &amp; consumer...</td>\n",
       "      <td>['1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n미국 연방거래...</td>\n",
       "      <td>The FTC has raised concerns regarding AI-relat...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What are the key considerations regarding AI f...   \n",
       "1  What are the key features and improvements of ...   \n",
       "2        What is the purpose of the AAAI Conference?   \n",
       "3  What role does content moderation play in the ...   \n",
       "4  What FTC concerns exist on AI comp. & consumer...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  ['∙ 3개국은 기반모델 전반에 대한 규제가 기술 중립적이고 위험 기반의 AI 규제...   \n",
       "1  ['1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n알리바바 클라...   \n",
       "2  ['Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 미국 소비자기술 협회(C...   \n",
       "3  ['£유튜브, 특정인을 모방한 AI 생성 콘텐츠에 대한 삭제 요청에도 대응 계획\\n...   \n",
       "4  ['1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n미국 연방거래...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  Key considerations regarding AI foundation mod...         simple   \n",
       "1  The key features and improvements of the LLM '...         simple   \n",
       "2  The purpose of the AAAI Conference is to advan...         simple   \n",
       "3  Content moderation plays a crucial role in AI ...         simple   \n",
       "4  The FTC has raised concerns regarding AI-relat...      reasoning   \n",
       "\n",
       "                                            metadata  episode_done  \n",
       "0  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True  \n",
       "1  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True  \n",
       "2  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True  \n",
       "3  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True  \n",
       "4  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/ragas_synthetic_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'contexts', 'ground_truth', 'evolution_type', 'metadata', 'episode_done'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "test_dataset = Dataset.from_pandas(df)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a3b71bfa2440cdaae1850fb4215f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'contexts', 'ground_truth', 'evolution_type', 'metadata', 'episode_done'],\n",
      "    num_rows: 10\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "\n",
    "def convert_to_list(example):\n",
    "    contexts = ast.literal_eval(example[\"contexts\"])\n",
    "    return {\"contexts\": contexts}\n",
    "\n",
    "\n",
    "test_dataset = test_dataset.map(convert_to_list)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n알리바바 클라우드, 최신 LLM ‘통이치엔원 2.0’ 공개\\nKEY Contents\\nn 알리바바 클라우드가 복잡한 지침 이해, 광고문구 작성, 추론, 암기 등에서 성능이 향상된 최신\\nLLM ‘통이치엔원 2.0’을 공개\\nn 알리바바 클라우드는 산업별로 특화된 생성 AI 모델을 공개하는 한편, 모델 개발과 애플리케이션\\n구축 절차를 간소화하는 올인원 AI 모델 구축 플랫폼도 출시\\n£알리바바의 통이치엔원 2.0, 주요 벤치마크 테스트에서 여타 LLM 능가\\nn 중국의 알리바바 클라우드가 2023년 10월 31일 열린 연례 기술 컨퍼런스에서 최신 LLM ‘통이\\n치엔원(Tongyi Qianwen) 2.0’을 공개\\n∙ 알리바바 클라우드는 통이치엔원 2.0이 2023년 4월 출시된 1.0 버전보다 복잡한 지침 이해,\\n광고문구 작성, 추론, 암기 등에서 성능이 향상되었다고 설명\\n∙ 통이치엔원 2.0은 언어 이해 테스트(MMLU), 수학(GSM8k), 질문 답변(ARC-C)과 같은 벤치마크\\n테스트에서 라마(Llama-2-70B)와 GPT-3.5를 비롯한 주요 AI 모델을 능가\\n∙ 통이치엔원 2.0은 알리바바 클라우드의 웹사이트와 모바일 앱을 통해 대중에 제공되며 개발자는\\nAPI를 통해 사용 가능\\nn 알리바바 클라우드는 여러 산업 영역에서 생성 AI를 활용해 사업 성과를 개선할 수 있도록 지원\\n하는 산업별 모델도 출시\\n∙ 산업 영역은 고객지원, 법률 상담, 의료, 금융, 문서관리, 오디오와 동영상 관리, 코드 개발, 캐릭터\\n제작을 포함\\nn 알리바바 클라우드는 급증하는 생성 AI 수요에 대응해 모델 개발과 애플리케이션 구축 절차를\\n간소화하는 올인원 AI 모델 구축 플랫폼 ‘젠AI(GenAI)’도 공개\\n∙ 이 플랫폼은 데이터 관리, 모델 배포와 평가, 신속한 엔지니어링을 위한 종합 도구 모음을 제공하여\\n다양한 기업들이 맞춤형 AI 모델을 한층 쉽게 개발할 수 있도록 지원']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[1][\"contexts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# 단계 1: 문서 로드(Load Documents)\n",
    "loader = PyMuPDFLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "# 단계 2: 문서 분할(Split Documents)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# 단계 3: 임베딩(Embedding) 생성\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# 단계 4: DB 생성(Create DB) 및 저장\n",
    "# 벡터스토어를 생성합니다.\n",
    "vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)\n",
    "\n",
    "# 단계 5: 검색기(Retriever) 생성\n",
    "# 문서에 포함되어 있는 정보를 검색하고 생성합니다.\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 단계 6: 프롬프트 생성(Create Prompt)\n",
    "# 프롬프트를 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "\n",
    "#Context: \n",
    "{context}\n",
    "\n",
    "#Question:\n",
    "{question}\n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n",
    "\n",
    "# 단계 7: 언어모델(LLM) 생성\n",
    "# 모델(LLM) 을 생성합니다.\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# 단계 8: 체인(Chain) 생성\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "배치 데이터셋을 생성합니다. 배치 데이터셋은 다량의 질문을 한 번에 처리할 때 용이합니다.\n",
    "\n",
    "- 배치: https://wikidocs.net/233345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What are the key considerations regarding AI foundation models in the context of EU regulations?',\n",
       " \"What are the key features and improvements of the LLM 'Tongyi Qianwen 2.0' compared to its previous version, including any changes in performance metrics, architectural design, and application areas?\",\n",
       " 'What is the purpose of the AAAI Conference?']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_dataset = [question for question in test_dataset[\"question\"]]\n",
    "batch_dataset[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`batch()` 를 호출하여 배치 데이터셋에 대한 답변을 받습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The key considerations regarding AI foundation models in the context of EU regulations include:\\n\\n1. **Regulatory Approach**: There is a significant debate on whether to impose regulations on AI foundation models. Some countries, like France, Germany, and Italy, oppose broad regulations on foundation models and instead propose a \"mandatory self-regulation\" approach. This involves the development of voluntary codes of conduct that companies must adhere to, rather than imposing direct regulations on the models themselves.\\n\\n2. **Model Cards**: These countries suggest that companies developing foundation models should create \"model cards\" that summarize the machine learning technology, the model\\'s capabilities, and its limitations. These model cards would help AI supervisory bodies assess compliance with the voluntary codes of conduct.\\n\\n3. **Impact Assessment and Sanctions**: The proposed approach includes a mechanism where AI supervisory bodies would evaluate compliance based on the model cards. If violations are found, immediate sanctions would not be imposed. Instead, there would be an analysis of the violation and its impact before any sanctions are applied.\\n\\n4. **Industry Influence**: The opposition to strict regulations is partly driven by concerns from AI companies in these countries. For instance, French AI company Mistral and German AI company Aleph Alpha have lobbied against stringent regulations, fearing that such measures could put them at a competitive disadvantage compared to companies in the US and China.\\n\\n5. **Risk-Based Regulation**: The proposed self-regulation approach aligns with the principle of risk-based AI regulation, which aims to be technology-neutral and focus on the specific risks associated with different AI applications rather than imposing blanket regulations on all AI technologies.\\n\\nThese considerations reflect the ongoing negotiations and differing viewpoints within the EU on how best to regulate AI foundation models while balancing innovation and risk management.',\n",
       " \"The key features and improvements of the LLM 'Tongyi Qianwen 2.0' compared to its previous version include:\\n\\n1. **Performance Enhancements**:\\n   - **Improved Capabilities**: Tongyi Qianwen 2.0 has enhanced performance in understanding complex instructions, writing advertising copy, reasoning, and memorization compared to the 1.0 version.\\n   - **Benchmark Tests**: It outperforms major AI models like Llama-2-70B and GPT-3.5 in various benchmark tests, including language understanding (MMLU), mathematics (GSM8k), and question answering (ARC-C).\\n\\n2. **Architectural and Functional Upgrades**:\\n   - **All-in-One AI Model Building Platform**: Alibaba Cloud has introduced an all-in-one AI model building platform called 'GenAI' to simplify the model development and application building process. This platform provides comprehensive tools for data management, model deployment, evaluation, and rapid engineering.\\n\\n3. **Application Areas**:\\n   - **Industry-Specific Models**: Alibaba Cloud has released industry-specific generative AI models to improve business outcomes across various sectors, including customer support, legal consultation, healthcare, finance, document management, audio and video management, code development, and character creation.\\n\\n4. **Accessibility**:\\n   - **Public Availability**: Tongyi Qianwen 2.0 is available to the public through Alibaba Cloud's website and mobile app, and developers can access it via API.\\n\\n5. **Future Plans**:\\n   - **Open Source Initiative**: Alibaba Cloud plans to open-source a model with 720 billion parameters by the end of the year to further support AI development.\\n\\nThese improvements and features make Tongyi Qianwen 2.0 a more powerful and versatile LLM compared to its predecessor.\",\n",
       " 'The purpose of the AAAI Conference on Artificial Intelligence is to promote AI research and provide opportunities for interaction among researchers, practitioners, scientists, students, and engineers in the AI field. The conference includes presentations on AI-related technologies, special tracks, invited speakers, workshops, tutorials, poster sessions, topic presentations, competitions, and exhibition programs.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = chain.batch(batch_dataset)\n",
    "answer[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM 이 생성한 답변을 'answer' 컬럼에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'answer' 컬럼 덮어쓰기 또는 추가\n",
    "if \"answer\" in test_dataset.column_names:\n",
    "    test_dataset = test_dataset.remove_columns([\"answer\"]).add_column(\"answer\", answer)\n",
    "else:\n",
    "    test_dataset = test_dataset.add_column(\"answer\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 답변 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Recall\n",
    "\n",
    "Context recall은 검색된 context가 LLM 이 생성한 답변과 얼마나 일치하는지를 측정합니다. \n",
    "\n",
    "이는 question, ground truth 및 검색된 context를 사용하여 계산되며, 값은 0에서 1 사이로, 높을수록 더 나은 성능을 나타냅니다. \n",
    "\n",
    "Ground truth 답변에서 context recall을 추정하기 위해, ground truth 답변의 각 주장이 검색된 context에 귀속될 수 있는지 분석됩니다. 이상적인 시나리오에서는 ground truth 답변의 모든 주장이 검색된 context에 귀속될 수 있어야 합니다. \n",
    "\n",
    "$$\\text{context recall} = \\frac{|\\text{GT claims that can be attributed to context}|}{|\\text{Number of claims in GT}|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Precision\n",
    "\n",
    "Context Precision은 contexts 내의 ground-truth 관련 항목들이 상위 순위에 있는지를 평가하는 지표입니다. 이상적으로는 모든 관련 chunks가 상위 순위에 나타나야 합니다. 이 지표는 question, ground_truth, 그리고 contexts를 사용하여 계산되며, 0에서 1 사이의 값을 가집니다. 높은 점수일수록 더 나은 정밀도를 나타냅니다.\n",
    "\n",
    "Context Precision@K의 계산식은 다음과 같습니다.\n",
    "\n",
    "$$\\text{Context Precision@K} = \\frac{\\sum_{k=1}^{K} (\\text{Precision@k} \\times v_k)}{\\text{Total number of relevant items in the top K results}}$$\n",
    "\n",
    "여기서 Precision@k는 다음과 같이 계산됩니다.\n",
    "\n",
    "$$\\text{Precision@k} = \\frac{\\text{true positives@k}}{(\\text{true positives@k + false positives@k})}$$\n",
    "\n",
    "K는 contexts의 총 chunk 수이며, $v_k \\in \\{0, 1\\}$은 순위 k에서의 관련성 지표입니다.\n",
    "\n",
    "이 지표는 정보 검색 시스템에서 검색된 컨텍스트의 품질을 평가하는 데 사용됩니다. 관련 정보가 얼마나 정확하게 상위 순위에 배치되었는지를 측정함으로써 시스템의 성능을 판단할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer Relevancy\n",
    "\n",
    "Answer Relevancy는 생성된 답변이 주어진 prompt에 얼마나 적절한지를 평가하는 지표입니다. 이 지표의 주요 특징과 계산 방법을 요약하면 다음과 같습니다:\n",
    "\n",
    "1. 목적: 생성된 답변의 관련성을 평가합니다.\n",
    "2. 점수 해석: 낮은 점수는 불완전하거나 중복 정보를 포함한 답변을, 높은 점수는 더 나은 관련성을 나타냅니다.\n",
    "3. 계산에 사용되는 요소: question, context, answer\n",
    "\n",
    "Answer Relevancy의 계산 방법:\n",
    "- 원래 question과 answer를 기반으로 생성된 인공적인 질문들 간의 평균 코사인 유사도로 정의됩니다.\n",
    "- 수식:\n",
    "\n",
    "$$\\text{answer relevancy} = \\frac{1}{N} \\sum_{i=1}^N \\cos(E_{g_i}, E_o)$$\n",
    "\n",
    "또는\n",
    "\n",
    "$$\\text{answer relevancy} = \\frac{1}{N} \\sum_{i=1}^N \\frac{E_{g_i} \\cdot E_o}{\\|E_{g_i}\\| \\|E_o\\|}$$\n",
    "\n",
    "여기서:\n",
    "- $E_{g_i}$는 생성된 질문 $i$의 임베딩\n",
    "- $E_o$는 원래 질문의 임베딩\n",
    "- $N$은 생성된 질문의 수 (기본값 3)\n",
    "\n",
    "주의사항:\n",
    "- 실제로는 점수가 대부분 0과 1 사이에 있지만, 코사인 유사도의 특성상 수학적으로 -1에서 1 사이의 값을 가질 수 있습니다.\n",
    "\n",
    "이 지표는 질문-답변 시스템의 성능을 평가하는 데 유용하며, 특히 생성된 답변이 원래 질문의 의도를 얼마나 잘 반영하는지를 측정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faithfulness\n",
    "\n",
    "Faithfulness는 생성된 답변의 사실적 일관성을 주어진 컨텍스트와 비교하여 측정하는 지표입니다. 주요 특징은 다음과 같습니다:\n",
    "\n",
    "1. 목적: 답변의 사실적 일관성을 컨텍스트와 비교하여 평가합니다.\n",
    "2. 계산 요소: 답변과 검색된 컨텍스트를 사용합니다.\n",
    "3. 점수 범위: 0에서 1 사이로 조정되며, 높을수록 더 좋습니다.\n",
    "\n",
    "Faithfulness 점수 계산 방법:\n",
    "\n",
    "$$\\text{Faithfulness score} = \\frac{|\\text{Number of claims in the generated answer that can be inferred from given context}|}{|\\text{Total number of claims in the generated answer}|}$$\n",
    "\n",
    "계산 과정:\n",
    "1. 생성된 답변에서 주장(claims)들을 식별합니다.\n",
    "2. 각 주장을 주어진 컨텍스트와 대조 검증하여 컨텍스트에서 추론 가능한지 확인합니다.\n",
    "3. 위 수식을 사용하여 점수를 계산합니다.\n",
    "\n",
    "예시:\n",
    "- 질문: \"아인슈타인은 어디서, 언제 태어났나요?\"\n",
    "- 컨텍스트: \"알버트 아인슈타인(1879년 3월 14일 출생)은 독일 출신의 이론 물리학자로, 역사상 가장 위대하고 영향력 있는 과학자 중 한 명으로 여겨집니다.\"\n",
    "- 높은 충실도 답변: \"아인슈타인은 1879년 3월 14일 독일에서 태어났습니다.\"\n",
    "- 낮은 충실도 답변: \"아인슈타인은 1879년 3월 20일 독일에서 태어났습니다.\"\n",
    "\n",
    "이 지표는 생성된 답변이 주어진 컨텍스트에 얼마나 충실한지를 평가하는 데 유용하며, 특히 질문-답변 시스템의 정확성과 신뢰성을 측정하는 데 중요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ecfcef8332a425fa26d3dce08a8744c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'context_precision': 0.8000, 'faithfulness': 0.6689, 'answer_relevancy': 0.7836, 'context_recall': 0.7667}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "result = evaluate(\n",
    "    dataset=test_dataset,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "    ],\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the key considerations regarding AI f...</td>\n",
       "      <td>[∙ 3개국은 기반모델 전반에 대한 규제가 기술 중립적이고 위험 기반의 AI 규제 ...</td>\n",
       "      <td>The key considerations regarding AI foundation...</td>\n",
       "      <td>Key considerations regarding AI foundation mod...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the key features and improvements of ...</td>\n",
       "      <td>[1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n알리바바 클라우...</td>\n",
       "      <td>The key features and improvements of the LLM '...</td>\n",
       "      <td>The key features and improvements of the LLM '...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.974629</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the purpose of the AAAI Conference?</td>\n",
       "      <td>[Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 미국 소비자기술 협회(CT...</td>\n",
       "      <td>The purpose of the AAAI Conference on Artifici...</td>\n",
       "      <td>The purpose of the AAAI Conference is to advan...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.983304</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What role does content moderation play in the ...</td>\n",
       "      <td>[£유튜브, 특정인을 모방한 AI 생성 콘텐츠에 대한 삭제 요청에도 대응 계획\\nn...</td>\n",
       "      <td>Content moderation plays a significant role in...</td>\n",
       "      <td>Content moderation plays a crucial role in AI ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.994695</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What FTC concerns exist on AI comp. &amp; consumer...</td>\n",
       "      <td>[1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n미국 연방거래위...</td>\n",
       "      <td>The FTC has several concerns regarding AI comp...</td>\n",
       "      <td>The FTC has raised concerns regarding AI-relat...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971904</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What are the key considerations regarding AI f...   \n",
       "1  What are the key features and improvements of ...   \n",
       "2        What is the purpose of the AAAI Conference?   \n",
       "3  What role does content moderation play in the ...   \n",
       "4  What FTC concerns exist on AI comp. & consumer...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [∙ 3개국은 기반모델 전반에 대한 규제가 기술 중립적이고 위험 기반의 AI 규제 ...   \n",
       "1  [1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n알리바바 클라우...   \n",
       "2  [Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 미국 소비자기술 협회(CT...   \n",
       "3  [£유튜브, 특정인을 모방한 AI 생성 콘텐츠에 대한 삭제 요청에도 대응 계획\\nn...   \n",
       "4  [1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n미국 연방거래위...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  The key considerations regarding AI foundation...   \n",
       "1  The key features and improvements of the LLM '...   \n",
       "2  The purpose of the AAAI Conference on Artifici...   \n",
       "3  Content moderation plays a significant role in...   \n",
       "4  The FTC has several concerns regarding AI comp...   \n",
       "\n",
       "                                        ground_truth  context_precision  \\\n",
       "0  Key considerations regarding AI foundation mod...                1.0   \n",
       "1  The key features and improvements of the LLM '...                1.0   \n",
       "2  The purpose of the AAAI Conference is to advan...                1.0   \n",
       "3  Content moderation plays a crucial role in AI ...                1.0   \n",
       "4  The FTC has raised concerns regarding AI-relat...                1.0   \n",
       "\n",
       "   faithfulness  answer_relevancy  context_recall  \n",
       "0      1.000000          1.000000        1.000000  \n",
       "1      0.966667          0.974629        1.000000  \n",
       "2      0.090909          0.983304        0.000000  \n",
       "3      0.000000          0.994695        1.000000  \n",
       "4      1.000000          0.971904        0.666667  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = result.to_pandas()\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_precision</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.974629</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.983304</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.994695</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971904</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995929</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.937892</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.977199</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   context_precision  faithfulness  answer_relevancy  context_recall\n",
       "0                1.0      1.000000          1.000000        1.000000\n",
       "1                1.0      0.966667          0.974629        1.000000\n",
       "2                1.0      0.090909          0.983304        0.000000\n",
       "3                1.0      0.000000          0.994695        1.000000\n",
       "4                1.0      1.000000          0.971904        0.666667\n",
       "5                0.0      1.000000          0.000000        1.000000\n",
       "6                1.0      1.000000          0.995929        1.000000\n",
       "7                1.0      0.333333          0.000000        0.000000\n",
       "8                1.0      0.631579          0.937892        1.000000\n",
       "9                0.0      0.666667          0.977199        1.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.loc[:, \"context_precision\":\"context_recall\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-lwwSZlnu-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
