{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50650ed4",
   "metadata": {},
   "source": [
    "## LCEL 인터페이스\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b78209c",
   "metadata": {},
   "source": [
    "사용자 정의 체인을 가능한 쉽게 만들 수 있도록, [`Runnable`](https://api.python.langchain.com/en/stable/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable) 프로토콜을 구현했습니다. \n",
    "\n",
    "`Runnable` 프로토콜은 대부분의 컴포넌트에 구현되어 있습니다.\n",
    "\n",
    "이는 표준 인터페이스로, 사용자 정의 체인을 정의하고 표준 방식으로 호출하는 것을 쉽게 만듭니다.\n",
    "표준 인터페이스에는 다음이 포함됩니다.\n",
    "\n",
    "- [`stream`](#stream): 응답의 청크를 스트리밍합니다.\n",
    "- [`invoke`](#invoke): 입력에 대해 체인을 호출합니다.\n",
    "- [`batch`](#batch): 입력 목록에 대해 체인을 호출합니다.\n",
    "\n",
    "비동기 메소드도 있습니다.\n",
    "\n",
    "- [`astream`](#async-stream): 비동기적으로 응답의 청크를 스트리밍합니다.\n",
    "- [`ainvoke`](#async-invoke): 비동기적으로 입력에 대해 체인을 호출합니다.\n",
    "- [`abatch`](#async-batch): 비동기적으로 입력 목록에 대해 체인을 호출합니다.\n",
    "- [`astream_log`](#async-stream-intermediate-steps): 최종 응답뿐만 아니라 발생하는 중간 단계를 스트리밍합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5a5ffc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4ccea96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "project_name='CH01-Basic-04-LCEL-Advanced-Gemini'\n",
      "LANGSMITH_PROJECT: CH01-Basic-04-LCEL-Advanced-Gemini\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH01-Basic-04-LCEL-Advanced-Gemini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59f2751",
   "metadata": {},
   "source": [
    "LCEL 문법을 사용하여 chain 을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "735d72ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from pydantic import SecretStr\n",
    "import os\n",
    "\n",
    "\n",
    "# 키 로드\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# LLM 생성\n",
    "# 모델 종류: https://ai.google.dev/gemini-api/docs/models?hl=ko\n",
    "# gemini-2.5-pro\n",
    "# gemini-2.5-flash\n",
    "# gemini-2.5-flash-lite\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    google_api_key=SecretStr(str(api_key)),\n",
    "    temperature=0.5,\n",
    ")\n",
    "# 주어진 토픽에 대한 농담을 요청하는 프롬프트 템플릿을 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\"{topic} 에 대하여 3문장으로 설명해줘.\")\n",
    "# 프롬프트와 모델을 연결하여 대화 체인을 생성합니다.\n",
    "chain = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb57eb05",
   "metadata": {},
   "source": [
    "## stream: 실시간 출력\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d62447d",
   "metadata": {},
   "source": [
    "이 함수는 `chain.stream` 메서드를 사용하여 주어진 토픽에 대한 데이터 스트림을 생성하고, 이 스트림을 반복하여 각 데이터의 내용(`content`)을 즉시 출력합니다. `end=\"\"` 인자는 출력 후 줄바꿈을 하지 않도록 설정하며, `flush=True` 인자는 출력 버퍼를 즉시 비우도록 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6304f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "멀티모달 AI는 텍스트, 이미지, 오디오 등 여러 형태의 데이터를 함께 이해하고 처리하는 인공지능 기술입니다. 이는 마치 인간이 보고, 듣고, 읽는 등 다양한 감각을 통해 세상을 종합적으로 인지하는 방식과 유사합니다. 따라서 더 풍부하고 정확한 정보를 바탕으로 상황을 깊이 이해하고, 복잡한 문제 해결이나 자연스러운 인간-AI 상호작용을 가능하게 합니다."
     ]
    }
   ],
   "source": [
    "# chain.stream 메서드를 사용하여 '멀티모달' 토픽에 대한 스트림을 생성하고 반복합니다.\n",
    "for token in chain.stream({\"topic\": \"멀티모달\"}):\n",
    "    # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6d71cf",
   "metadata": {},
   "source": [
    "## invoke: 호출\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0feebe",
   "metadata": {},
   "source": [
    "`chain` 객체의 `invoke` 메서드는 주제를 인자로 받아 해당 주제에 대한 처리를 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fb8bf06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ChatGPT는 OpenAI가 개발한 **인공지능 챗봇**입니다. 방대한 데이터를 학습하여 **사람처럼 자연스러운 대화를 나누고 텍스트를 생성**하는 능력을 가졌습니다. 질문 답변, 글쓰기, 요약, 번역 등 **다양한 작업을 수행하며 사용자에게 도움**을 제공합니다.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain 객체의 invoke 메서드를 호출하고, 'ChatGPT'라는 주제로 딕셔너리를 전달합니다.\n",
    "chain.invoke({\"topic\": \"ChatGPT\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6618b9d",
   "metadata": {},
   "source": [
    "## batch: 배치(단위 실행)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c34bad",
   "metadata": {},
   "source": [
    "함수 `chain.batch`는 여러 개의 딕셔너리를 포함하는 리스트를 인자로 받아, 각 딕셔너리에 있는 `topic` 키의 값을 사용하여 일괄 처리를 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "687d223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 토픽 리스트를 batch 처리하는 함수 호출\n",
    "answer = chain.batch([{\"topic\": \"Gemini\"}, {\"topic\": \"Instagram\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef2ec33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Gemini는 구글이 개발한 최신 인공지능 모델입니다. 텍스트, 이미지, 오디오 등 다양한 형태의 정보를 이해하고 생성할 수 있는 '멀티모달' 능력을 갖춘 것이 특징입니다. 이는 복잡한 추론과 문제 해결 능력을 바탕으로 구글의 다양한 제품과 서비스에 활용되고 있습니다.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answer)\n",
    "answer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20d1299d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Instagram은 사진과 짧은 동영상을 공유하며 소통하는 시각 중심의 소셜 미디어 플랫폼입니다. 사용자들은 피드, 스토리, 릴스 등을 통해 자신의 일상이나 관심사를 공유하고, 다른 사람들의 게시물을 탐색하며 '좋아요'나 댓글로 교류합니다. 이를 통해 친구, 가족과 연결되고, 새로운 콘텐츠를 발견하며, 다양한 커뮤니티와 교류할 수 있습니다.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970a4f5a",
   "metadata": {},
   "source": [
    "`max_concurrency` 매개변수를 사용하여 동시 요청 수를 설정할 수 있습니다\n",
    "\n",
    "`config` 딕셔너리는 `max_concurrency` 키를 통해 동시에 처리할 수 있는 최대 작업 수를 설정합니다. 여기서는 최대 3개의 작업을 동시에 처리하도록 설정되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d5398d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ChatGPT는 OpenAI가 개발한 대규모 언어 모델(LLM) 기반의 인공지능 챗봇입니다. 사용자의 질문이나 지시에 따라 사람과 유사한 텍스트를 생성하며 자연스러운 대화가 가능합니다. 정보 탐색, 글쓰기, 요약, 번역 등 광범위한 분야에서 사용자에게 유용한 도움을 제공합니다.',\n",
       " 'Instagram은 사진과 짧은 동영상을 공유하는 데 중점을 둔 세계적인 소셜 미디어 플랫폼입니다. 사용자들은 자신의 일상을 시각적으로 공유하고, 친구나 관심사를 팔로우하며 소통합니다. 피드, 스토리, 릴스 등 다양한 기능을 통해 콘텐츠를 탐색하고 상호작용할 수 있습니다.',\n",
       " '멀티모달은 텍스트, 이미지, 음성, 영상 등 여러 가지 형태의 데이터를 동시에 이해하고 처리하는 인공지능 기술을 말합니다. 이는 마치 사람이 시각, 청각 등 다양한 감각을 활용하여 세상을 인지하듯, AI가 더 풍부한 정보를 통합하여 상황을 파악하게 합니다. 이를 통해 AI는 더욱 복합적인 질문에 답하거나 현실 세계를 더 정확하게 인식하며, 사람과 자연스럽게 소통하는 능력을 향상시킵니다.',\n",
       " '프로그래밍은 컴퓨터에게 특정 작업을 수행하도록 지시하는 과정입니다. 이는 파이썬, 자바 등 프로그래밍 언어라는 약속된 규칙을 사용하여 코드를 작성하는 방식으로 이루어집니다. 최종적으로는 이러한 지시를 통해 컴퓨터가 문제 해결, 자동화 등 원하는 기능을 수행하는 소프트웨어나 애플리케이션을 만드는 것입니다.',\n",
       " '머신러닝은 컴퓨터가 **명시적인 프로그래밍 없이** 데이터를 분석하여 **스스로 학습**하고 패턴을 찾아내는 인공지능의 한 분야입니다. 이는 대량의 데이터 속에서 숨겨진 규칙이나 경향을 파악하여 미래를 예측하거나 새로운 결정을 내리는 데 활용됩니다. 스팸 메일 분류, 이미지 인식, 추천 시스템 등 다양한 분야에서 복잡한 문제 해결에 기여하고 있습니다.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch(\n",
    "    [\n",
    "        {\"topic\": \"ChatGPT\"},\n",
    "        {\"topic\": \"Instagram\"},\n",
    "        {\"topic\": \"멀티모달\"},\n",
    "        {\"topic\": \"프로그래밍\"},\n",
    "        {\"topic\": \"머신러닝\"},\n",
    "    ],\n",
    "    config={\"max_concurrency\": 3},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec64e4fd",
   "metadata": {},
   "source": [
    "## async stream: 비동기 스트림\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbb21a3",
   "metadata": {},
   "source": [
    "함수 `chain.astream`은 비동기 스트림을 생성하며, 주어진 토픽에 대한 메시지를 비동기적으로 처리합니다.\n",
    "\n",
    "비동기 for 루프(`async for`)를 사용하여 스트림에서 메시지를 순차적으로 받아오고, `print` 함수를 통해 메시지의 내용(`s.content`)을 즉시 출력합니다. `end=\"\"`는 출력 후 줄바꿈을 하지 않도록 설정하며, `flush=True`는 출력 버퍼를 강제로 비워 즉시 출력되도록 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f8a9e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YouTube는 구글 소유의 세계 최대 동영상 공유 플랫폼입니다. 사용자들은 엔터테인먼트, 교육, 뉴스 등 다양한 주제의 영상을 업로드하고 시청하며, 댓글로 소통할 수 있습니다. 전 세계 누구나 자유롭게 콘텐츠를 제작하고 소비하는 글로벌 미디어 허브 역할을 합니다."
     ]
    }
   ],
   "source": [
    "# 비동기 스트림을 사용하여 'YouTube' 토픽의 메시지를 처리합니다.\n",
    "async for token in chain.astream({\"topic\": \"YouTube\"}):\n",
    "    # 메시지 내용을 출력합니다. 줄바꿈 없이 바로 출력하고 버퍼를 비웁니다.\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33cb7e9",
   "metadata": {},
   "source": [
    "## async invoke: 비동기 호출\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763738b7",
   "metadata": {},
   "source": [
    "`chain` 객체의 `ainvoke` 메서드는 비동기적으로 주어진 인자를 사용하여 작업을 수행합니다. 여기서는 `topic`이라는 키와 `NVDA`(엔비디아의 티커) 라는 값을 가진 딕셔너리를 인자로 전달하고 있습니다. 이 메서드는 특정 토픽에 대한 처리를 비동기적으로 요청하는 데 사용될 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2038557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비동기 체인 객체의 'ainvoke' 메서드를 호출하여 'NVDA' 토픽을 처리합니다.\n",
    "my_process = chain.ainvoke({\"topic\": \"NVDA\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea8077cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 41\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.5-flash\"\n  }\n  quota_value: 10\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 39\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAioRpcError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/para/project/langchain-kr-teddy/.venv/lib/python3.11/site-packages/google/api_core/grpc_helpers_async.py:81\u001b[39m, in \u001b[36m_WrappedUnaryResponseMixin.__await__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     response = \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call.\u001b[34m__await__\u001b[39m()\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/para/project/langchain-kr-teddy/.venv/lib/python3.11/site-packages/grpc/aio/_interceptor.py:472\u001b[39m, in \u001b[36m_InterceptedUnaryResponseMixin.__await__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    471\u001b[39m call = \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._interceptors_task.\u001b[34m__await__\u001b[39m()\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m response = \u001b[38;5;28;01myield from\u001b[39;00m call.\u001b[34m__await__\u001b[39m()\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/para/project/langchain-kr-teddy/.venv/lib/python3.11/site-packages/grpc/aio/_call.py:327\u001b[39m, in \u001b[36m_UnaryResponseMixin.__await__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m _create_rpc_error(\n\u001b[32m    328\u001b[39m             \u001b[38;5;28mself\u001b[39m._cython_call._initial_metadata,\n\u001b[32m    329\u001b[39m             \u001b[38;5;28mself\u001b[39m._cython_call._status,\n\u001b[32m    330\u001b[39m         )\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mAioRpcError\u001b[39m: <AioRpcError of RPC that terminated with:\n\tstatus = StatusCode.RESOURCE_EXHAUSTED\n\tdetails = \"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.250.198.42:443 {grpc_message:\"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\", grpc_status:8, created_time:\"2025-07-28T13:57:16.208915559+09:00\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mResourceExhausted\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 비동기로 처리되는 프로세스가 완료될 때까지 기다립니다.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m my_process\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/para/project/langchain-kr-teddy/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:3088\u001b[39m, in \u001b[36mRunnableSequence.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3086\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3087\u001b[39m                 part = functools.partial(step.ainvoke, input_, config)\n\u001b[32m-> \u001b[39m\u001b[32m3088\u001b[39m             input_ = \u001b[38;5;28;01mawait\u001b[39;00m coro_with_context(part(), context, create_task=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   3089\u001b[39m     \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3090\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/para/project/langchain-kr-teddy/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:417\u001b[39m, in \u001b[36mBaseChatModel.ainvoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    407\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mainvoke\u001b[39m(\n\u001b[32m    409\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    414\u001b[39m     **kwargs: Any,\n\u001b[32m    415\u001b[39m ) -> BaseMessage:\n\u001b[32m    416\u001b[39m     config = ensure_config(config)\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m     llm_result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agenerate_prompt(\n\u001b[32m    418\u001b[39m         [\u001b[38;5;28mself\u001b[39m._convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[32m    419\u001b[39m         stop=stop,\n\u001b[32m    420\u001b[39m         callbacks=config.get(\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    421\u001b[39m         tags=config.get(\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    422\u001b[39m         metadata=config.get(\u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    423\u001b[39m         run_name=config.get(\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    424\u001b[39m         run_id=config.pop(\u001b[33m\"\u001b[39m\u001b[33mrun_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    425\u001b[39m         **kwargs,\n\u001b[32m    426\u001b[39m     )\n\u001b[32m    427\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m, llm_result.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/para/project/langchain-kr-teddy/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:991\u001b[39m, in \u001b[36mBaseChatModel.agenerate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    982\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    983\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34magenerate_prompt\u001b[39m(\n\u001b[32m    984\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    988\u001b[39m     **kwargs: Any,\n\u001b[32m    989\u001b[39m ) -> LLMResult:\n\u001b[32m    990\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m991\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agenerate(\n\u001b[32m    992\u001b[39m         prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/para/project/langchain-kr-teddy/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:949\u001b[39m, in \u001b[36mBaseChatModel.agenerate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    936\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[32m    937\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    938\u001b[39m             *[\n\u001b[32m    939\u001b[39m                 run_manager.on_llm_end(\n\u001b[32m   (...)\u001b[39m\u001b[32m    947\u001b[39m             ]\n\u001b[32m    948\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions[\u001b[32m0\u001b[39m]\n\u001b[32m    950\u001b[39m flattened_outputs = [\n\u001b[32m    951\u001b[39m     LLMResult(generations=[res.generations], llm_output=res.llm_output)  \u001b[38;5;66;03m# type: ignore[list-item, union-attr]\u001b[39;00m\n\u001b[32m    952\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[32m    953\u001b[39m ]\n\u001b[32m    954\u001b[39m llm_output = \u001b[38;5;28mself\u001b[39m._combine_llm_outputs([res.llm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/para/project/langchain-kr-teddy/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel._agenerate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1115\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1116\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._agenerate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._agenerate(\n\u001b[32m   1118\u001b[39m         messages, stop=stop, run_manager=run_manager, **kwargs\n\u001b[32m   1119\u001b[39m     )\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1121\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._agenerate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/para/project/langchain-kr-teddy/.venv/lib/python3.11/site-packages/langchain_google_genai/chat_models.py:1324\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._agenerate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   1309\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()._agenerate(\n\u001b[32m   1310\u001b[39m         messages, stop, run_manager, **updated_kwargs\n\u001b[32m   1311\u001b[39m     )\n\u001b[32m   1313\u001b[39m request = \u001b[38;5;28mself\u001b[39m._prepare_request(\n\u001b[32m   1314\u001b[39m     messages,\n\u001b[32m   1315\u001b[39m     stop=stop,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1322\u001b[39m     tool_choice=tool_choice,\n\u001b[32m   1323\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1324\u001b[39m response: GenerateContentResponse = \u001b[38;5;28;01mawait\u001b[39;00m _achat_with_retry(\n\u001b[32m   1325\u001b[39m     request=request,\n\u001b[32m   1326\u001b[39m     **kwargs,\n\u001b[32m   1327\u001b[39m     generation_method=\u001b[38;5;28mself\u001b[39m.async_client.generate_content,\n\u001b[32m   1328\u001b[39m     metadata=\u001b[38;5;28mself\u001b[39m.default_metadata,\n\u001b[32m   1329\u001b[39m )\n\u001b[32m   1330\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/para/project/langchain-kr-teddy/.venv/lib/python3.11/site-packages/langchain_google_genai/chat_models.py:243\u001b[39m, in \u001b[36m_achat_with_retry\u001b[39m\u001b[34m(generation_method, **kwargs)\u001b[39m\n\u001b[32m    240\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _achat_with_retry(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/para/project/langchain-kr-teddy/.venv/lib/python3.11/site-packages/tenacity/asyncio/__init__.py:189\u001b[39m, in \u001b[36mAsyncRetrying.wraps.<locals>.async_wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    188\u001b[39m async_wrapped.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m copy(fn, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/para/project/langchain-kr-teddy/.venv/lib/python3.11/site-packages/tenacity/asyncio/__init__.py:111\u001b[39m, in \u001b[36mAsyncRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    109\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     do = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter(retry_state=retry_state)\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    113\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/para/project/langchain-kr-teddy/.venv/lib/python3.11/site-packages/tenacity/asyncio/__init__.py:153\u001b[39m, in \u001b[36mAsyncRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    151\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m action(retry_state)\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/para/project/langchain-kr-teddy/.venv/lib/python3.11/site-packages/tenacity/_utils.py:99\u001b[39m, in \u001b[36mwrap_to_async_func.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args: typing.Any, **kwargs: typing.Any) -> typing.Any:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/para/project/langchain-kr-teddy/.venv/lib/python3.11/site-packages/tenacity/__init__.py:418\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    416\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/para/project/langchain-kr-teddy/.venv/lib/python3.11/site-packages/tenacity/__init__.py:185\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.13/lib/python3.11/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.13/lib/python3.11/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/para/project/langchain-kr-teddy/.venv/lib/python3.11/site-packages/tenacity/asyncio/__init__.py:114\u001b[39m, in \u001b[36mAsyncRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         result = \u001b[38;5;28;01mawait\u001b[39;00m fn(*args, **kwargs)\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    116\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/para/project/langchain-kr-teddy/.venv/lib/python3.11/site-packages/langchain_google_genai/chat_models.py:241\u001b[39m, in \u001b[36m_achat_with_retry.<locals>._achat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    237\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[32m    238\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    239\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/para/project/langchain-kr-teddy/.venv/lib/python3.11/site-packages/langchain_google_genai/chat_models.py:234\u001b[39m, in \u001b[36m_achat_with_retry.<locals>._achat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    231\u001b[39m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_achat_with_retry\u001b[39m(**kwargs: Any) -> Any:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m generation_method(**kwargs)\n\u001b[32m    235\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m InvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    236\u001b[39m         \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n\u001b[32m    237\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[32m    238\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    239\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/para/project/langchain-kr-teddy/.venv/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/async_client.py:444\u001b[39m, in \u001b[36mGenerativeServiceAsyncClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    441\u001b[39m \u001b[38;5;28mself\u001b[39m._client._validate_universe_domain()\n\u001b[32m    443\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m444\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m rpc(\n\u001b[32m    445\u001b[39m     request,\n\u001b[32m    446\u001b[39m     retry=retry,\n\u001b[32m    447\u001b[39m     timeout=timeout,\n\u001b[32m    448\u001b[39m     metadata=metadata,\n\u001b[32m    449\u001b[39m )\n\u001b[32m    451\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    452\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/para/project/langchain-kr-teddy/.venv/lib/python3.11/site-packages/google/api_core/retry_async.py:223\u001b[39m, in \u001b[36mAsyncRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    219\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    220\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    221\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    222\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m retry_target(\n\u001b[32m    224\u001b[39m     target,\n\u001b[32m    225\u001b[39m     \u001b[38;5;28mself\u001b[39m._predicate,\n\u001b[32m    226\u001b[39m     sleep_generator,\n\u001b[32m    227\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout,\n\u001b[32m    228\u001b[39m     on_error=on_error,\n\u001b[32m    229\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/para/project/langchain-kr-teddy/.venv/lib/python3.11/site-packages/google/api_core/retry_async.py:121\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m target()\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.wait_for(\n\u001b[32m    122\u001b[39m             target(),\n\u001b[32m    123\u001b[39m             timeout=(deadline_dt - datetime_helpers.utcnow()).total_seconds(),\n\u001b[32m    124\u001b[39m         )\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.13/lib/python3.11/asyncio/tasks.py:489\u001b[39m, in \u001b[36mwait_for\u001b[39m\u001b[34m(fut, timeout)\u001b[39m\n\u001b[32m    486\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fut.done():\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    491\u001b[39m     fut.remove_done_callback(cb)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.13/lib/python3.11/asyncio/tasks.py:694\u001b[39m, in \u001b[36m_wrap_awaitable\u001b[39m\u001b[34m(awaitable)\u001b[39m\n\u001b[32m    687\u001b[39m \u001b[38;5;129m@types\u001b[39m.coroutine\n\u001b[32m    688\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrap_awaitable\u001b[39m(awaitable):\n\u001b[32m    689\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Helper for asyncio.ensure_future().\u001b[39;00m\n\u001b[32m    690\u001b[39m \n\u001b[32m    691\u001b[39m \u001b[33;03m    Wraps awaitable (an object with __await__) into a coroutine\u001b[39;00m\n\u001b[32m    692\u001b[39m \u001b[33;03m    that will later be wrapped in a Task by ensure_future().\u001b[39;00m\n\u001b[32m    693\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m694\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01myield from\u001b[39;00m awaitable.\u001b[34m__await__\u001b[39m())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/para/project/langchain-kr-teddy/.venv/lib/python3.11/site-packages/google/api_core/grpc_helpers_async.py:84\u001b[39m, in \u001b[36m_WrappedUnaryResponseMixin.__await__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m rpc_error:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(rpc_error) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrpc_error\u001b[39;00m\n",
      "\u001b[31mResourceExhausted\u001b[39m: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.5-flash\"\n  }\n  quota_value: 10\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 39\n}\n]"
     ]
    }
   ],
   "source": [
    "# 비동기로 처리되는 프로세스가 완료될 때까지 기다립니다.\n",
    "await my_process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c466177",
   "metadata": {},
   "source": [
    "## async batch: 비동기 배치\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da01286",
   "metadata": {},
   "source": [
    "함수 `abatch`는 비동기적으로 일련의 작업을 일괄 처리합니다.\n",
    "\n",
    "이 예시에서는 `chain` 객체의 `abatch` 메서드를 사용하여 `topic` 에 대한 작업을 비동기적으로 처리하고 있습니다.\n",
    "\n",
    "`await` 키워드는 해당 비동기 작업이 완료될 때까지 기다리는 데 사용됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53a00116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 토픽에 대해 비동기적으로 일괄 처리를 수행합니다.\n",
    "my_abatch_process = chain.abatch(\n",
    "    [{\"topic\": \"YouTube\"}, {\"topic\": \"Instagram\"}, {\"topic\": \"Facebook\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8823211b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['유튜브는 전 세계에서 가장 큰 동영상 공유 플랫폼입니다. 사용자들은 교육, 엔터테인먼트, 뉴스 등 매우 다양한 주제의 영상을 업로드하고 시청하며 공유할 수 있습니다. 이를 통해 전 세계 수많은 사람들이 정보를 얻고 소통하며 즐거움을 누리는 주요 채널로 자리매김했습니다.',\n",
       " 'Instagram은 사진과 짧은 동영상을 공유하며 소통하는 대표적인 소셜 미디어 플랫폼입니다. 사용자들은 자신의 일상을 시각적으로 표현하고, 친구나 관심사를 가진 사람들과 팔로우하며 교류합니다. 다양한 콘텐츠를 탐색하고 새로운 정보를 얻거나 영감을 받을 수 있는 공간입니다.',\n",
       " '페이스북은 전 세계 수십억 명이 사용하는 가장 큰 소셜 네트워킹 플랫폼 중 하나입니다. 사용자들은 친구 및 가족과 연결하고, 개인적인 소식, 사진, 동영상 등을 공유하며 소통할 수 있습니다. 또한 관심사 기반의 그룹에 참여하거나, 다양한 뉴스 및 정보를 접하고, 비즈니스 페이지를 통해 정보를 얻는 등 다채로운 활동이 가능합니다.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 비동기로 처리되는 일괄 처리 프로세스가 완료될 때까지 기다립니다.\n",
    "await my_abatch_process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0b9377",
   "metadata": {},
   "source": [
    "## Parallel: 병렬성\n",
    "\n",
    "LangChain Expression Language가 병렬 요청을 지원하는 방법을 살펴봅시다.\n",
    "예를 들어, `RunnableParallel`을 사용할 때, 각 요소를 병렬로 실행합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a387f0",
   "metadata": {},
   "source": [
    "`langchain_core.runnables` 모듈의 `RunnableParallel` 클래스를 사용하여 두 가지 작업을 병렬로 실행하는 예시를 보여줍니다.\n",
    "\n",
    "`ChatPromptTemplate.from_template` 메서드를 사용하여 주어진 `country`에 대한 **수도** 와 **면적** 을 구하는 두 개의 체인(`chain1`, `chain2`)을 만듭니다.\n",
    "\n",
    "이 체인들은 각각 `model`과 파이프(`|`) 연산자를 통해 연결됩니다. 마지막으로, `RunnableParallel` 클래스를 사용하여 이 두 체인을 `capital`와 `area`이라는 키로 결합하여 동시에 실행할 수 있는 `combined` 객체를 생성합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2b42d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# {country} 의 수도를 물어보는 체인을 생성합니다.\n",
    "chain1 = (\n",
    "    PromptTemplate.from_template(\"{country} 의 수도는 어디야?\")\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# {country} 의 면적을 물어보는 체인을 생성합니다.\n",
    "chain2 = (\n",
    "    PromptTemplate.from_template(\"{country} 의 면적은 얼마야?\")\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 위의 2개 체인을 동시에 생성하는 병렬 실행 체인을 생성합니다.\n",
    "combined = RunnableParallel(capital=chain1, area=chain2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb0a2b8",
   "metadata": {},
   "source": [
    "`chain1.invoke()` 함수는 `chain1` 객체의 `invoke` 메서드를 호출합니다.\n",
    "\n",
    "이때, `country`이라는 키에 `대한민국`라는 값을 가진 딕셔너리를 인자로 전달합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f04dbce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국의 수도는 **서울**입니다.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain1 를 실행합니다.\n",
    "chain1.invoke({\"country\": \"대한민국\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa819963",
   "metadata": {},
   "source": [
    "이번에는 `chain2.invoke()` 를 호출합니다. `country` 키에 다른 국가인 `미국` 을 전달합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b055566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'미국의 총 면적은 약 **983만 4천 제곱킬로미터 (km²)** 입니다.\\n\\n이는 약 **380만 제곱마일 (sq mi)** 에 해당합니다.\\n\\n이 수치는 육지 및 내수면을 포함한 총 면적이며, 자료 출처에 따라 약간의 차이가 있을 수 있습니다.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain2 를 실행합니다.\n",
    "chain2.invoke({\"country\": \"미국\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5f3bbb",
   "metadata": {},
   "source": [
    "`combined` 객체의 `invoke` 메서드는 주어진 `country`에 대한 처리를 수행합니다.\n",
    "\n",
    "이 예제에서는 `대한민국`라는 주제를 `invoke` 메서드에 전달하여 실행합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fa82d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capital': '대한민국의 수도는 **서울**입니다.',\n",
       " 'area': '대한민국의 면적은 **약 100,363 제곱킬로미터(km²)** 입니다.\\n\\n일반적으로는 **약 10만 제곱킬로미터**라고도 많이 알려져 있습니다.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 병렬 실행 체인을 실행합니다.\n",
    "combined.invoke({\"country\": \"대한민국\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459613b6",
   "metadata": {},
   "source": [
    "### 배치에서의 병렬 처리\n",
    "\n",
    "병렬 처리는 다른 실행 가능한 코드와 결합될 수 있습니다.\n",
    "배치와 병렬 처리를 사용해 보도록 합시다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1621ce",
   "metadata": {},
   "source": [
    "`chain1.batch` 함수는 여러 개의 딕셔너리를 포함하는 리스트를 인자로 받아, 각 딕셔너리에 있는 \"topic\" 키에 해당하는 값을 처리합니다. 이 예시에서는 \"대한민국\"와 \"미국\"라는 두 개의 토픽을 배치 처리하고 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0754e0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['대한민국의 수도는 **서울**입니다.', '미국의 수도는 **워싱턴 D.C.** 입니다.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 배치 처리를 수행합니다.\n",
    "chain1.batch([{\"country\": \"대한민국\"}, {\"country\": \"미국\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb73505",
   "metadata": {},
   "source": [
    "`chain2.batch` 함수는 여러 개의 딕셔너리를 리스트 형태로 받아, 일괄 처리(batch)를 수행합니다.\n",
    "\n",
    "이 예시에서는 `대한민국`와 `미국`라는 두 가지 국가에 대한 처리를 요청합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f076b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['대한민국(남한)의 면적은 약 **100,363 제곱킬로미터(km²)**입니다.\\n\\n보통 **약 10만 제곱킬로미터**라고도 많이 이야기합니다.\\n\\n이는 한반도 전체 면적(약 22만 제곱킬로미터)의 절반이 조금 안 되는 수준입니다.',\n",
       " '미국의 총 면적은 약 **983만 4천 제곱킬로미터 (km²)** 입니다.\\n\\n이는 약 **380만 5천 제곱마일 (mi²)** 에 해당합니다.\\n\\n이 면적에는 육지와 내수면(강, 호수 등)이 모두 포함됩니다. 정확한 수치는 측정 기준에 따라 약간의 차이가 있을 수 있습니다.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 배치 처리를 수행합니다.\n",
    "chain2.batch([{\"country\": \"대한민국\"}, {\"country\": \"미국\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40da05e",
   "metadata": {},
   "source": [
    "`combined.batch` 함수는 주어진 데이터를 배치로 처리하는 데 사용됩니다. 이 예시에서는 두 개의 딕셔너리 객체를 포함하는 리스트를 인자로 받아 각각 `대한민국`와 `미국` 두 나라에 대한 데이터를 배치 처리합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aeec745e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'capital': '대한민국의 수도는 **서울**입니다.',\n",
       "  'area': '대한민국의 면적은 약 **100,363 제곱킬로미터 (km²)** 입니다.\\n\\n이는 남한만의 면적을 기준으로 하며, 측정 시기나 방법에 따라 약간의 차이가 있을 수 있습니다.\\n\\n참고로, 한반도 전체 면적(남한+북한)은 약 22만 제곱킬로미터입니다.'},\n",
       " {'capital': '미국의 수도는 **워싱턴 D.C.**입니다.',\n",
       "  'area': '미국의 면적은 약 **9,834,000 제곱 킬로미터 (km²)** 입니다.\\n\\n이는 약 **3,797,000 제곱 마일 (mi²)** 에 해당합니다.\\n\\n이 면적은 주로 육지 면적과 내수면(호수, 강 등)을 포함한 총 면적을 기준으로 합니다.'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 주어진 데이터를 배치로 처리합니다.\n",
    "combined.batch([{\"country\": \"대한민국\"}, {\"country\": \"미국\"}])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
