{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b47e94eb",
   "metadata": {},
   "source": [
    "# GPT4All\n",
    "\n",
    "[GitHub:nomic-ai/gpt4all](https://github.com/nomic-ai/gpt4all)은 코드, 스토리, 대화를 포함한 방대한 양의 깨끗한 어시스턴트 데이터로 학습된 오픈 소스 챗봇 생태계입니다.\n",
    "\n",
    "이 예제에서는 LangChain을 사용하여 `GPT4All` 모델과 상호 작용하는 방법에 대해 설명합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2927024",
   "metadata": {},
   "source": [
    "## 설치방법\n",
    "\n",
    "- [pip 를 활용한 설치 방법](https://github.com/nomic-ai/gpt4all/blob/main/gpt4all-bindings/python/README.md)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73379234",
   "metadata": {},
   "source": [
    "- `%pip` 매직 명령어를 사용하여 `gpt4all` 패키지를 최신 버전으로 업그레이드합니다.\n",
    "- `--upgrade` 옵션을 통해 이미 설치된 패키지도 최신 버전으로 업그레이드합니다.\n",
    "- `--quiet` 옵션을 사용하여 설치 과정에서 출력되는 메시지를 최소화합니다.\n",
    "- `> /dev/null` 리다이렉션을 통해 설치 과정에서 발생하는 출력을 `/dev/null` 디바이스로 보내 출력을 숨깁니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5efa7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  gpt4all > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc95d0c2",
   "metadata": {},
   "source": [
    "### Import GPT4All\n",
    "\n",
    "GPT4All을 임포트하는 방법은 다음과 같습니다.\n",
    "\n",
    "python\n",
    "from gpt4all import GPT4All\n",
    "\n",
    "이 코드는 `gpt4all` 모듈에서 `GPT4All` 클래스를 임포트합니다.\n",
    "\n",
    "`GPT4All`은 GPT-3와 유사한 대규모 언어 모델로, 다양한 자연어 처리 작업에 활용될 수 있습니다.\n",
    "\n",
    "이 모듈을 사용하면 GPT4All 모델을 간편하게 로드하고 추론에 활용할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127159e7",
   "metadata": {},
   "source": [
    "- `GPT4All` 언어 모델을 사용하여 프롬프트에 대한 응답을 생성하는 `LLMChain`을 구현합니다.\n",
    "- `PromptTemplate`을 사용하여 프롬프트 템플릿을 정의합니다.\n",
    "- `StreamingStdOutCallbackHandler`를 사용하여 언어 모델의 출력을 실시간으로 스트리밍합니다.\n",
    "- `LLMChain`을 초기화할 때 언어 모델, 프롬프트 템플릿, 콜백 핸들러를 전달합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243c4e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import GPT4All\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\",\n",
    ")\n",
    "\n",
    "# GPT4All 언어 모델 초기화\n",
    "# model_path는 GPT4All 모델 파일의 경로를 지정\n",
    "llm = GPT4All(\n",
    "    model_path=\"./models/gpt4all-model.bin\",\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# LLMChain을 사용하여 프롬프트와 언어 모델을 연결\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# 체인을 실행하여 제품명에 따른 회사명 제안 생성\n",
    "product = \"colorful socks\"\n",
    "result = chain.run(product)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce296b67",
   "metadata": {},
   "source": [
    "### Set Up Question to pass to LLM\n",
    "\n",
    "LLM에 전달할 질문을 설정하는 과정입니다.\n",
    "\n",
    "이 단계에서는 LLM에 입력으로 제공할 질문을 준비합니다.\n",
    "\n",
    "질문은 문자열 형태로 구성되며, 이후 LLM에 전달되어 처리됩니다.\n",
    "\n",
    "적절한 질문을 설정하는 것은 LLM으로부터 원하는 답변을 얻는 데 중요한 역할을 합니다.\n",
    "\n",
    "질문은 명확하고 구체적으로 작성되어야 하며, LLM이 이해할 수 있는 형식으로 제공되어야 합니다.\n",
    "\n",
    "이 과정에서는 사용자의 입력을 받아 질문을 생성하거나, 미리 정의된 질문 템플릿을 활용할 수 있습니다.\n",
    "\n",
    "질문 설정이 완료되면 LLM에 질문을 전달하고 답변을 받아오는 다음 단계로 진행됩니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13f7adb",
   "metadata": {},
   "source": [
    "다음은 주어진 코드에 대한 요약문입니다:\n",
    "\n",
    "`PromptTemplate` 클래스를 사용하여 프롬프트 템플릿을 정의합니다.\n",
    "\n",
    "- `template` 변수에 프롬프트 템플릿 문자열을 할당합니다.\n",
    "  - 템플릿에는 `{question}` 플레이스홀더가 포함되어 있습니다.\n",
    "  - 템플릿의 내용은 질문과 \"Answer: Let's think step by step.\"로 구성됩니다.\n",
    "- `PromptTemplate.from_template()` 메서드를 사용하여 `template`을 기반으로 `PromptTemplate` 인스턴스를 생성합니다.\n",
    "- 생성된 `PromptTemplate` 인스턴스는 `prompt` 변수에 할당됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cba73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"  # 질문과 답변 템플릿을 정의합니다.\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    template\n",
    ")  # 템플릿을 기반으로 프롬프트 객체를 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be058ae2",
   "metadata": {},
   "source": [
    "### Specify Model\n",
    "\n",
    "로컬에서 실행하려면 호환되는 ggml 형식의 모델을 다운로드하세요.\n",
    "\n",
    "[gpt4all 페이지](https://gpt4all.io/index.html)에는 유용한 `Model Explorer` 섹션이 있습니다:\n",
    "\n",
    "- 관심 있는 모델을 선택하세요.\n",
    "- UI를 사용하여 다운로드하고 `.bin` 파일을 `local_path`(아래 참고)로 이동시키세요.\n",
    "\n",
    "더 많은 정보를 원하시면 https://github.com/nomic-ai/gpt4all 을 방문하세요.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93efa0fe",
   "metadata": {},
   "source": [
    "- `local_path` 변수에 로컬 파일 경로(\"./models/ggml-gpt4all-l13b-snoozy.bin\")를 할당합니다.\n",
    "  - 이 경로는 사용자가 원하는 로컬 파일 경로로 대체할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f61a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = (\n",
    "    \"./models/ggml-gpt4all-l13b-snoozy.bin\"  # 원하는 로컬 파일 경로로 대체하세요.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df58479b",
   "metadata": {},
   "source": [
    "GPT4All 모델을 사용하여 토큰 단위로 출력을 스트리밍하는 방법을 보여줍니다.\n",
    "\n",
    "- `StreamingStdOutCallbackHandler`를 사용하여 콜백 리스트를 생성합니다.\n",
    "- `GPT4All` 클래스를 초기화할 때 `callbacks` 매개변수에 콜백 리스트를 전달하고, `verbose` 매개변수를 `True`로 설정합니다.\n",
    "- 사용자 정의 모델을 사용하려면 `backend` 매개변수를 추가합니다. 지원되는 백엔드는 GPT4All Python 문서에서 확인할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd66e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 콜백은 토큰 단위 스트리밍을 지원합니다.\n",
    "callbacks = [StreamingStdOutCallbackHandler()]\n",
    "\n",
    "# 콜백 관리자에 전달하려면 verbose가 필요합니다.\n",
    "llm = GPT4All(model=local_path, callbacks=callbacks, verbose=True)\n",
    "\n",
    "# 사용자 정의 모델을 사용하려면 backend 매개변수를 추가하세요.\n",
    "# 지원되는 백엔드는 https://docs.gpt4all.io/gpt4all_python.html 을 확인하세요.\n",
    "llm = GPT4All(model=local_path, backend=\"gptj\", callbacks=callbacks, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175b3144",
   "metadata": {},
   "source": [
    "`LLMChain`을 사용하여 프롬프트와 언어 모델을 연결하는 체인을 생성합니다.\n",
    "\n",
    "- `prompt` 변수에는 사용할 프롬프트 템플릿이 할당되어 있습니다.\n",
    "- `llm` 변수에는 사용할 언어 모델(Language Model) 객체가 할당되어 있습니다.\n",
    "- `LLMChain` 생성자에 `prompt`와 `llm`을 전달하여 체인을 초기화합니다.\n",
    "- 생성된 `llm_chain` 객체를 통해 프롬프트에 입력을 제공하면 언어 모델을 사용하여 출력을 생성할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef64e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    # 프롬프트를 지정합니다.\n",
    "    prompt=prompt,\n",
    "    # 언어 모델을 지정합니다.\n",
    "    llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e544f7a",
   "metadata": {},
   "source": [
    "`llm_chain` 객체를 사용하여 주어진 질문에 대한 답변을 생성합니다.\n",
    "\n",
    "- `question` 변수에 \"What NFL team won the Super Bowl in the year Justin Bieber was born?\"라는 질문을 할당합니다.\n",
    "- `llm_chain.run()` 메서드에 `question`을 전달하여 실행합니다.\n",
    "- `llm_chain`은 사전에 정의되고 초기화된 언어 모델 체인으로 추정되며, 주어진 질문에 대한 답변을 생성할 것으로 예상됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68f99ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Justin Bieber가 태어난 해에 슈퍼볼에서 우승한 NFL 팀은 어느 팀인가요?\n",
    "question = \"What NFL team won the Super Bowl in the year Justin Bieber was born?\"\n",
    "\n",
    "llm_chain.run(question)  # 질문에 대한 답변을 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b357547",
   "metadata": {},
   "source": [
    "Justin Bieber는 1994년 3월 1일에 태어났습니다.\n",
    "\n",
    "1994년에는 Dallas Cowboys가 Super Bowl XXVIII에서 우승했습니다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
