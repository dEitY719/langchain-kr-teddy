{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b95818c",
   "metadata": {},
   "source": [
    "다양한 언어 처리 및 AI 관련 라이브러리를 설치하는 명령어입니다. `langchain_community`, `tiktoken`, `langchain-openai`, `langchainhub`, `chromadb`, `langchain`, `langgraph` 등의 패키지를 포함합니다.\n",
    "\n",
    "이러한 패키지들은 언어 처리, AI 모델 통합, 데이터베이스 관리, 그래프 기반 데이터 처리 등 다양한 기능을 제공하여, 언어 기반 AI 애플리케이션 개발에 필수적인 도구들을 포함하고 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f28ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langchain_community tiktoken langchain-openai langchainhub chromadb langchain langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa6fb7f",
   "metadata": {},
   "source": [
    "# LangGraph Retrieval Agent\n",
    "\n",
    "[검색 에이전트](https://python.langchain.com/docs/use_cases/question_answering/conversational_retrieval_agents)는 인덱스에서 검색할지 여부에 대한 결정을 내리고 싶을 때 유용합니다.\n",
    "\n",
    "검색 에이전트를 구현하기 위해서는 LLM에 검색 도구에 대한 접근 권한을 제공하기만 하면 됩니다.\n",
    "\n",
    "이를 [LangGraph](https://python.langchain.com/docs/langgraph)에 통합할 수 있습니다.\n",
    "\n",
    "## Retriever\n",
    "\n",
    "첫 번째로, 3개의 블로그 게시물을 인덱싱합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "064d5c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# api key\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3adc68",
   "metadata": {},
   "source": [
    "본 코드는 웹 기반 문서 로더, 텍스트 분할기, 벡터 저장소, 그리고 임베딩을 활용하여 문서를 처리하고 검색 가능한 형태로 변환하는 과정을 담고 있습니다.\n",
    "\n",
    "`WebBaseLoader`를 사용하여 주어진 URL 목록에서 문서를 로드합니다.\n",
    "\n",
    "`RecursiveCharacterTextSplitter`는 문서를 특정 크기의 청크로 분할하는 데 사용됩니다.\n",
    "\n",
    "분할된 문서는 `Chroma` 벡터 저장소에 저장되며, `OpenAIEmbeddings`를 사용하여 임베딩됩니다.\n",
    "\n",
    "이후, 저장된 문서는 검색을 위해 검색기(`retriever`)로 변환됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95cf41bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=100, chunk_overlap=50\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# 벡터 데이터베이스에 문서 추가\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247cd249",
   "metadata": {},
   "source": [
    "LangChain의 `create_retriever_tool` 함수를 사용하여 특정 주제에 대한 블로그 게시물을 검색하고 정보를 반환하는 도구를 생성합니다. 이 예제에서는 Lilian Weng의 블로그 게시물 중 LLM 에이전트, 프롬프트 엔지니어링, LLM에 대한 적대적 공격에 관한 정보를 검색합니다.\n",
    "\n",
    "생성된 도구는 `ToolExecutor` 클래스의 인스턴스에 등록되어 실행될 준비가 됩니다. `ToolExecutor`는 등록된 모든 도구를 관리하고 실행하는 역할을 담당합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4166abda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolExecutor\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "# 릴리안 웡의 블로그 게시물에 대한 정보를 검색하고 반환하는 도구를 생성합니다.\n",
    "tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retrieve_blog_posts\",\n",
    "    \"Search and return information about Lilian Weng blog posts on LLM agents, prompt engineering, and adversarial attacks on LLMs.\",\n",
    ")\n",
    "\n",
    "tools = [tool]\n",
    "\n",
    "\n",
    "# 도구들을 실행할 ToolExecutor 객체를 생성합니다.\n",
    "tool_executor = ToolExecutor(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d047f938",
   "metadata": {},
   "source": [
    "## Agent state\n",
    "\n",
    "그래프를 정의 해야합니다.\n",
    "\n",
    "- 각 노드에 전달하는 `state` 객체입니다.\n",
    "\n",
    "- `AgentState` 는 `messages`의 리스트가 될 것입니다.\n",
    "\n",
    "- 그래프의 각 노드는 `AgentState`에 추가할 것입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "998e8b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # AgentState 클래스는 메시지 시퀀스를 포함하는 타입 딕셔너리입니다.\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56d4095",
   "metadata": {},
   "source": [
    "## 노드와 엣지\n",
    "\n",
    "우리는 agentic RAG 그래프를 다음과 같이 구성할 수 있습니다:\n",
    "\n",
    "- 상태는 메시지의 집합입니다\n",
    "- 각 노드는 상태를 업데이트(추가)합니다\n",
    "- 조건부 엣지는 다음에 방문할 노드를 결정합니다\n",
    "\n",
    "![](https://teddylee777.github.io/images/2024-03-06-langgraph-agentic-rag/nodes-and-edges.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95eb882",
   "metadata": {},
   "source": [
    "본 코드는 문서 검색, 관련성 평가, 질문 재구성, 그리고 답변 생성을 포함하는 정보 검색 및 처리 프로세스를 구현합니다.\n",
    "\n",
    "첫 단계에서는 에이전트가 추가 정보를 검색해야 하는지 결정합니다(`should_retrieve`). 다음으로, 검색된 문서가 주어진 질문과 관련이 있는지 평가합니다(`grade_documents`). 이후, 질문을 재구성하여 더 나은 질문을 생성합니다(`rewrite`). 마지막으로, 최종적으로 검색된 문서를 바탕으로 답변을 생성합니다(`generate`).\n",
    "\n",
    "각 단계는 특정 입력에 따라 동작하며, 이 과정은 대화형 에이전트나 정보 검색 시스템에서 유용하게 사용될 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09e34c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain_core.messages import BaseMessage, FunctionMessage\n",
    "from langchain.output_parsers.openai_tools import PydanticToolsParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import ToolInvocation\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Edges\n",
    "\n",
    "\n",
    "def should_retrieve(state):\n",
    "    \"\"\"\n",
    "    에이전트가 더 많은 정보를 검색해야 하는지 또는 프로세스를 종료해야 하는지 결정합니다.\n",
    "\n",
    "    이 함수는 상태의 마지막 메시지에서 함수 호출을 확인합니다. 함수 호출이 있으면 정보 검색 프로세스를 계속합니다. 그렇지 않으면 프로세스를 종료합니다.\n",
    "\n",
    "    Args:\n",
    "        state (messages): 현재 상태\n",
    "\n",
    "    Returns:\n",
    "        str: 검색 프로세스를 \"계속\"하거나 \"종료\"하는 결정\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---DECIDE TO RETRIEVE---\")\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    # 함수 호출이 없으면 종료합니다.\n",
    "    if \"function_call\" not in last_message.additional_kwargs:\n",
    "        print(\"---DECISION: DO NOT RETRIEVE / DONE---\")\n",
    "        return \"end\"\n",
    "    # 그렇지 않으면 함수 호출이 있으므로 계속합니다.\n",
    "    else:\n",
    "        print(\"---DECISION: RETRIEVE---\")\n",
    "        return \"continue\"\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    검색된 문서가 질문과 관련이 있는지 여부를 결정합니다.\n",
    "\n",
    "    Args:\n",
    "        state (messages): 현재 상태\n",
    "\n",
    "    Returns:\n",
    "        str: 문서가 관련이 있는지 여부에 대한 결정\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK RELEVANCE---\")\n",
    "\n",
    "    # 데이터 모델\n",
    "    class grade(BaseModel):\n",
    "        \"\"\"관련성 검사를 위한 이진 점수.\"\"\"\n",
    "\n",
    "        binary_score: str = Field(description=\"'yes' 또는 'no'의 관련성 점수\")\n",
    "\n",
    "    # LLM\n",
    "    model = ChatOpenAI(\n",
    "        temperature=0, model=\"gpt-4-0125-preview\", streaming=True)\n",
    "\n",
    "    # 도구\n",
    "    grade_tool_oai = convert_to_openai_tool(grade)\n",
    "\n",
    "    # 도구와 강제 호출을 사용한 LLM\n",
    "    llm_with_tool = model.bind(\n",
    "        tools=[convert_to_openai_tool(grade_tool_oai)],\n",
    "        tool_choice={\"type\": \"function\", \"function\": {\"name\": \"grade\"}},\n",
    "    )\n",
    "\n",
    "    # 파서\n",
    "    parser_tool = PydanticToolsParser(tools=[grade])\n",
    "\n",
    "    # 프롬프트\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    # 체인\n",
    "    chain = prompt | llm_with_tool | parser_tool\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    question = messages[0].content\n",
    "    docs = last_message.content\n",
    "\n",
    "    score = chain.invoke({\"question\": question, \"context\": docs})\n",
    "\n",
    "    grade = score[0].binary_score\n",
    "\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: DOCS RELEVANT---\")\n",
    "        return \"yes\"\n",
    "\n",
    "    else:\n",
    "        print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
    "        print(grade)\n",
    "        return \"no\"\n",
    "\n",
    "\n",
    "# Nodes\n",
    "\n",
    "\n",
    "def agent(state):\n",
    "    \"\"\"\n",
    "    현재 상태를 기반으로 에이전트 모델을 호출하여 응답을 생성합니다. 질문에 따라 검색 도구를 사용하여 검색을 결정하거나 단순히 종료합니다.\n",
    "\n",
    "    Args:\n",
    "        state (messages): 현재 상태\n",
    "\n",
    "    Returns:\n",
    "        dict: 메시지에 에이전트 응답이 추가된 업데이트된 상태\n",
    "    \"\"\"\n",
    "    print(\"---CALL AGENT---\")\n",
    "    messages = state[\"messages\"]\n",
    "    model = ChatOpenAI(temperature=0, streaming=True,\n",
    "                       model=\"gpt-4-0125-preview\")\n",
    "    functions = [format_tool_to_openai_function(t) for t in tools]\n",
    "    model = model.bind_functions(functions)\n",
    "    response = model.invoke(messages)\n",
    "    # 이것은 기존 목록에 추가될 것이므로 리스트를 반환합니다.\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    도구를 사용하여 검색을 실행합니다.\n",
    "\n",
    "    Args:\n",
    "        state (messages): 현재 상태\n",
    "\n",
    "    Returns:\n",
    "        dict: 검색된 문서가 추가된 업데이트된 상태\n",
    "    \"\"\"\n",
    "    print(\"---EXECUTE RETRIEVAL---\")\n",
    "    messages = state[\"messages\"]\n",
    "    # 계속 조건을 기반으로 마지막 메시지가 함수 호출을 포함하고 있음을 알 수 있습니다.\n",
    "    last_message = messages[-1]\n",
    "    # 함수 호출에서 ToolInvocation을 구성합니다.\n",
    "    action = ToolInvocation(\n",
    "        tool=last_message.additional_kwargs[\"function_call\"][\"name\"],\n",
    "        tool_input=json.loads(\n",
    "            last_message.additional_kwargs[\"function_call\"][\"arguments\"]\n",
    "        ),\n",
    "    )\n",
    "    # 도구 실행자를 호출하고 응답을 받습니다.\n",
    "    response = tool_executor.invoke(action)\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "\n",
    "    # 이것은 기존 목록에 추가될 것이므로 리스트를 반환합니다.\n",
    "    return {\"messages\": [function_message]}\n",
    "\n",
    "\n",
    "def rewrite(state):\n",
    "    \"\"\"\n",
    "    질문을 변형하여 더 나은 질문을 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        state (messages): 현재 상태\n",
    "\n",
    "    Returns:\n",
    "        dict: 재구성된 질문이 추가된 업데이트된 상태\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "\n",
    "    msg = [\n",
    "        HumanMessage(\n",
    "            content=f\"\"\" \\n \n",
    "    Look at the input and try to reason about the underlying semantic intent / meaning. \\n \n",
    "    Here is the initial question:\n",
    "    \\n ------- \\n\n",
    "    {question} \n",
    "    \\n ------- \\n\n",
    "    Formulate an improved question: \"\"\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # 평가자\n",
    "    model = ChatOpenAI(\n",
    "        temperature=0, model=\"gpt-4-0125-preview\", streaming=True)\n",
    "    response = model.invoke(msg)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    답변 생성\n",
    "\n",
    "    Args:\n",
    "        state (messages): 현재 상태\n",
    "\n",
    "    Returns:\n",
    "         dict: 재구성된 질문이 추가된 업데이트된 상태\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    question = messages[0].content\n",
    "    docs = last_message.content\n",
    "\n",
    "    # 프롬프트\n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "    # LLM\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4-turbo-preview\",\n",
    "                     temperature=0, streaming=True)\n",
    "\n",
    "    # 후처리\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    # 체인\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    # 실행\n",
    "    response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3d09f3",
   "metadata": {},
   "source": [
    "## Graph\n",
    "\n",
    "- 에이전트로 시작하며, `call_model`\n",
    "- 에이전트는 함수를 호출할지 결정합니다\n",
    "- 만약 호출한다면, 도구(검색기)를 호출하는 `action`을 수행합니다\n",
    "- 그 다음 메시지(`state`)에 도구의 출력을 추가하여 에이전트를 호출합니다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587a31d3",
   "metadata": {},
   "source": [
    "StateGraph 클래스는 `langgraph.graph` 모듈에서 제공되며, 상태 기반 그래프를 정의하고 관리하는 데 사용됩니다.\n",
    "\n",
    "이 클래스를 활용하여 에이전트의 상태, 정보 검색, 정보 재작성, 정보 생성 등의 노드를 순환하는 워크플로우를 구성할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f901759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "# langgraph.graph에서 StateGraph와 END를 가져옵니다.\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# 순환할 노드들을 정의합니다.\n",
    "workflow.add_node(\"agent\", agent)  # 에이전트 노드를 추가합니다.\n",
    "workflow.add_node(\"retrieve\", retrieve)  # 정보 검색 노드를 추가합니다.\n",
    "workflow.add_node(\"rewrite\", rewrite)  # 정보 재작성 노드를 추가합니다.\n",
    "workflow.add_node(\"generate\", generate)  # 정보 생성 노드를 추가합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9c97b7",
   "metadata": {},
   "source": [
    "주어진 코드는 워크플로우를 설정하여 에이전트의 결정에 따라 문서를 검색하거나 다른 작업을 수행하는 과정을 정의합니다.\n",
    "\n",
    "처음에는 `agent` 노드를 시작점으로 설정하고, 에이전트의 결정(`should_retrieve`)에 따라 `retrieve` 노드를 호출하거나 작업을 종료합니다.\n",
    "\n",
    "`retrieve` 노드 이후에는 문서의 평가(`grade_documents`)를 통해 `generate` 또는 `rewrite` 작업을 결정하고, 각각의 경로를 따라 최종적으로 작업을 마무리하거나 에이전트로 돌아가는 과정을 포함합니다.\n",
    "\n",
    "이 과정은 복잡한 결정과 작업의 흐름을 관리하는 데 사용될 수 있으며, 최종적으로 워크플로우를 컴파일하여 실행 가능한 애플리케이션을 생성합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b18f2562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에이전트 노드 호출하여 검색 여부 결정\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# 검색 여부 결정\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    # 에이전트 결정 평가\n",
    "    should_retrieve,\n",
    "    {\n",
    "        # 도구 노드 호출\n",
    "        \"continue\": \"retrieve\",\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# `action` 노드 호출 후 진행될 경로\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    # 에이전트 결정 평가\n",
    "    grade_documents,\n",
    "    {\n",
    "        \"yes\": \"generate\",\n",
    "        \"no\": \"rewrite\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "workflow.add_edge(\"rewrite\", \"agent\")\n",
    "\n",
    "# 컴파일\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c65ca1e",
   "metadata": {},
   "source": [
    "본 코드는 `langchain_core.messages` 모듈의 `HumanMessage` 클래스를 활용하여 사용자의 질문을 정의하고, `app.stream` 메소드를 통해 이 질문에 대한 응답을 스트리밍하는 과정을 보여줍니다.\n",
    "\n",
    "각 응답은 키와 값의 쌍으로 구성되며, `pprint` 모듈을 사용하여 가독성 높게 출력됩니다.\n",
    "\n",
    "이 과정은 특정 질문에 대한 AI 기반의 응답을 실시간으로 처리하고 출력하는 데 사용될 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48d27562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL AGENT---\n",
      "\"Output from node 'agent':\"\n",
      "'---'\n",
      "{ 'messages': [ AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"types of agent memory\"}', 'name': 'retrieve_blog_posts'}})]}\n",
      "'\\n---\\n'\n",
      "---DECIDE TO RETRIEVE---\n",
      "---DECISION: RETRIEVE---\n",
      "---EXECUTE RETRIEVAL---\n",
      "\"Output from node 'retrieve':\"\n",
      "'---'\n",
      "{ 'messages': [ FunctionMessage(content='Table of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.', name='retrieve_blog_posts')]}\n",
      "'\\n---\\n'\n",
      "---CHECK RELEVANCE---\n",
      "---DECISION: DOCS RELEVANT---\n",
      "---GENERATE---\n",
      "\"Output from node 'generate':\"\n",
      "'---'\n",
      "{ 'messages': [ 'Lilian Weng discusses two types of agent memory: short-term '\n",
      "                'memory, which involves in-context learning and utilizes the '\n",
      "                \"model's immediate memory to learn, and long-term memory, \"\n",
      "                'which allows an agent to retain and recall information over '\n",
      "                'extended periods, often through the use of an external vector '\n",
      "                'store for fast retrieval.']}\n",
      "'\\n---\\n'\n",
      "\"Output from node '__end__':\"\n",
      "'---'\n",
      "{ 'messages': [ HumanMessage(content='What does Lilian Weng say about the types of agent memory?'),\n",
      "                AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"types of agent memory\"}', 'name': 'retrieve_blog_posts'}}),\n",
      "                FunctionMessage(content='Table of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.', name='retrieve_blog_posts'),\n",
      "                'Lilian Weng discusses two types of agent memory: short-term '\n",
      "                'memory, which involves in-context learning and utilizes the '\n",
      "                \"model's immediate memory to learn, and long-term memory, \"\n",
      "                'which allows an agent to retain and recall information over '\n",
      "                'extended periods, often through the use of an external vector '\n",
      "                'store for fast retrieval.']}\n",
      "'\\n---\\n'\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# HumanMessage 객체를 사용하여 질문 메시지를 정의합니다.\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\n",
    "            content=\"What does Lilian Weng say about the types of agent memory?\"\n",
    "        )\n",
    "    ]\n",
    "}\n",
    "# app.stream을 통해 입력된 메시지에 대한 출력을 스트리밍합니다.\n",
    "for output in app.stream(inputs):\n",
    "    # 출력된 결과에서 키와 값을 순회합니다.\n",
    "    for key, value in output.items():\n",
    "        # 노드의 이름과 해당 노드에서 나온 출력을 출력합니다.\n",
    "        pprint.pprint(f\"Output from node '{key}':\")\n",
    "        pprint.pprint(\"---\")\n",
    "        # 출력 값을 예쁘게 출력합니다.\n",
    "        pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "    # 각 출력 사이에 구분선을 추가합니다.\n",
    "    pprint.pprint(\"\\n---\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
