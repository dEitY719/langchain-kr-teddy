{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_conversation = \"\"\"From: í…Œë”” (teddy@teddynote.com)\n",
    "To: ì´ì€ì±„ ëŒ€ë¦¬ë‹˜ (eunchae@teddyinternational.me)\n",
    "Subject: RAG ì†”ë£¨ì…˜ ì‹œì—° ê´€ë ¨ ë¯¸íŒ… ì œì•ˆ\n",
    "\n",
    "ì•ˆë…•í•˜ì„¸ìš”, ì´ì€ì±„ ëŒ€ë¦¬ë‹˜,\n",
    "\n",
    "ì €ëŠ” í…Œë””ë…¸íŠ¸ì˜ í…Œë””ì…ë‹ˆë‹¤. ìµœê·¼ ê·€ì‚¬ì—ì„œ AIë¥¼ í™œìš©í•œ í˜ì‹ ì ì¸ ì†”ë£¨ì…˜ì„ ëª¨ìƒ‰ ì¤‘ì´ë¼ëŠ” ì†Œì‹ì„ ë“¤ì—ˆìŠµë‹ˆë‹¤. í…Œë””ë…¸íŠ¸ëŠ” AI ë° RAG ì†”ë£¨ì…˜ ë¶„ì•¼ì—ì„œ ë‹¤ì–‘í•œ ê²½í—˜ê³¼ ë…¸í•˜ìš°ë¥¼ ê°€ì§„ ê¸°ì—…ìœ¼ë¡œ, ê·€ì‚¬ì˜ ìš”êµ¬ì— ë§ëŠ” ìµœì ì˜ ì†”ë£¨ì…˜ì„ ì œê³µí•  ìˆ˜ ìˆë‹¤ê³  ìë¶€í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì €í¬ í…Œë””ë…¸íŠ¸ì˜ RAG ì†”ë£¨ì…˜ì€ ê·€ì‚¬ì˜ ë°ì´í„° í™œìš©ì„ ê·¹ëŒ€í™”í•˜ê³ , ì‹¤ì‹œê°„ìœ¼ë¡œ ì •í™•í•œ ì •ë³´ ì œê³µì„ í†µí•´ ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ì‚¬ê²°ì •ì„ ì§€ì›í•˜ëŠ” ë° íƒì›”í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. ì´ ì†”ë£¨ì…˜ì€ íŠ¹íˆ ë‹¤ì–‘í•œ ì‚°ì—…ì—ì„œì˜ ì„±ê³µì ì¸ ì ìš© ì‚¬ë¡€ë¥¼ í†µí•´ ê·¸ íš¨ê³¼ë¥¼ ì…ì¦í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê·€ì‚¬ì™€ì˜ í˜‘ë ¥ ê°€ëŠ¥ì„±ì„ ë…¼ì˜í•˜ê³ , ì €í¬ RAG ì†”ë£¨ì…˜ì˜ êµ¬ì²´ì ì¸ ê¸°ëŠ¥ê³¼ ì ìš© ë°©ì•ˆì„ ì‹œì—°í•˜ê¸° ìœ„í•´ ë¯¸íŒ…ì„ ì œì•ˆë“œë¦½ë‹ˆë‹¤. ë‹¤ìŒ ì£¼ ëª©ìš”ì¼(7ì›” 18ì¼) ì˜¤ì „ 10ì‹œì— ê·€ì‚¬ ì‚¬ë¬´ì‹¤ì—ì„œ ë§Œë‚˜ ëµ ìˆ˜ ìˆì„ê¹Œìš”?\n",
    "\n",
    "ë¯¸íŒ… ì‹œê°„ì„ ì¡°ìœ¨í•˜ê¸° ì–´ë ¤ìš°ì‹œë‹¤ë©´, í¸í•˜ì‹  ë‹¤ë¥¸ ì¼ì •ì„ ì•Œë ¤ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤. ì´ì€ì±„ ëŒ€ë¦¬ë‹˜ê³¼ì˜ ì†Œì¤‘í•œ ë§Œë‚¨ì„ í†µí•´ ìƒí˜¸ ë°œì „ì ì¸ ë…¼ì˜ê°€ ì´ë£¨ì–´ì§€ê¸¸ ê¸°ëŒ€í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê°ì‚¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "í…Œë””\n",
    "í…Œë””ë…¸íŠ¸ AI ì†”ë£¨ì…˜íŒ€\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# ì´ë©”ì¼ ë³¸ë¬¸ìœ¼ë¡œë¶€í„° ì£¼ìš” ì—”í‹°í‹° ì¶”ì¶œ\n",
    "class EmailSummary(BaseModel):\n",
    "    person: str = Field(description=\"ë©”ì¼ì„ ë³´ë‚¸ ì‚¬ëŒ\")\n",
    "    company: str = Field(description=\"ë©”ì¼ì„ ë³´ë‚¸ ì‚¬ëŒì˜ íšŒì‚¬ ì •ë³´\")\n",
    "    email: str = Field(description=\"ë©”ì¼ì„ ë³´ë‚¸ ì‚¬ëŒì˜ ì´ë©”ì¼ ì£¼ì†Œ\")\n",
    "    subject: str = Field(description=\"ë©”ì¼ ì œëª©\")\n",
    "    summary: str = Field(description=\"ë©”ì¼ ë³¸ë¬¸ì„ ìš”ì•½í•œ í…ìŠ¤íŠ¸\")\n",
    "    date: str = Field(description=\"ë©”ì¼ ë³¸ë¬¸ì— ì–¸ê¸‰ëœ ë¯¸íŒ… ë‚ ì§œì™€ ì‹œê°„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(EmailSummary.__mro__)\n",
    "print(type(EmailSummary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LCEL êµ¬ì¡°\n",
    "\n",
    "# chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "from common.gemini_llm_factory import GeminiLLMFactory\n",
    "\n",
    "llm_factory = GeminiLLMFactory()\n",
    "llm = llm_factory.get_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "# PydanticOutputParser ìƒì„±\n",
    "output_parser = PydanticOutputParser(pydantic_object=EmailSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are a helpful assistant. Please answer the following questions in KOREAN.\n",
    "\n",
    "#QUESTION:\n",
    "ë‹¤ìŒì˜ ì´ë©”ì¼ ë‚´ìš© ì¤‘ì—ì„œ ì£¼ìš” ë‚´ìš©ì„ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.\n",
    "\n",
    "#EMAIL CONVERSATION:\n",
    "{email_conversation}\n",
    "\n",
    "#FORMAT:\n",
    "{format}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# format ì— PydanticOutputParserì˜ ë¶€ë¶„ í¬ë§·íŒ…(partial) ì¶”ê°€\n",
    "prompt = prompt.partial(format=output_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²´ì¸ ìƒì„±\n",
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²´ì¸ ì‹¤í–‰\n",
    "answer = chain.invoke({\"email_conversation\": email_conversation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ê²€ìƒ‰: SERP API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì°¸ê³ : https://serpapi.com/integrations/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"SERPAPI_API_KEY\"] = (\n",
    "    \"a5b65676a84fabb861004e0da985676a972ab55da755b3d8a157926ba9cfd8d4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "\n",
    "params = {\"engine\": \"google\", \"gl\": \"kr\", \"hl\": \"ko\", \"num\": \"3\"}\n",
    "\n",
    "search = SerpAPIWrapper(params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.run(\"ì‚¼ì„±ì „ì\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer.email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"{answer.person} {answer.company} {answer.email}\"\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result = search.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result = eval(search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ìƒ‰ ê²°ê³¼\n",
    "search_result_string = \"\\n\".join(search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "report_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"ë‹¹ì‹ ì€ ì´ë©”ì¼ì˜ ì£¼ìš” ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìš”ì•½ ì •ë¦¬í•´ ì£¼ëŠ” ì „ë¬¸ê°€ ì…ë‹ˆë‹¤.\n",
    "ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ë‹¤ìŒì˜ ì´ë©”ì¼ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë³´ê³ ì„œ í˜•ì‹ì˜ ìš”ì•½ì„ ì‘ì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "ì£¼ì–´ì§„ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì–‘ì‹(format)ì— ë§ì¶”ì–´ ìš”ì•½ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n",
    "\n",
    "#Information:\n",
    "- Sender: {sender}\n",
    "- Additional Information about sender: {additional_information}\n",
    "- Company: {company}\n",
    "- Email: {email}\n",
    "- Subject: {subject}\n",
    "- Summary: {summary}\n",
    "- Date: {date}\n",
    "\n",
    "#Format(in markdown format):\n",
    "ğŸ™‡â€â™‚ï¸ ë³´ë‚¸ ì‚¬ëŒ:\n",
    "- (ë³´ë‚¸ ì‚¬ëŒì˜ ì´ë¦„, íšŒì‚¬ ì •ë³´)\n",
    "\n",
    "ğŸ“§ ì´ë©”ì¼ ì£¼ì†Œ:\n",
    "- (ë³´ë‚¸ ì‚¬ëŒì˜ ì´ë©”ì¼ ì£¼ì†Œ)\n",
    "\n",
    "ğŸ˜ ë³´ë‚¸ ì‚¬ëŒê³¼ ê´€ë ¨í•˜ì—¬ ê²€ìƒ‰ëœ ì¶”ê°€ ì •ë³´:\n",
    "- (ê²€ìƒ‰ëœ ì¶”ê°€ ì •ë³´)\n",
    "\n",
    "âœ… ì£¼ìš” ë‚´ìš©:\n",
    "- (ì´ë©”ì¼ ì œëª©, ìš”ì•½)\n",
    "\n",
    "â° ì¼ì •:\n",
    "- (ë¯¸íŒ… ë‚ ì§œ ë° ì‹œê°„)\n",
    "\n",
    "#Answer:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "from common.gemini_llm_factory import GeminiLLMFactory\n",
    "\n",
    "llm_factory = GeminiLLMFactory()\n",
    "llm = llm_factory.get_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_chain = report_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_response = report_chain.invoke(\n",
    "    {\n",
    "        \"sender\": answer.person,\n",
    "        \"additional_information\": search_result_string,\n",
    "        \"company\": answer.company,\n",
    "        \"email\": answer.email,\n",
    "        \"subject\": answer.subject,\n",
    "        \"summary\": answer.summary,\n",
    "        \"date\": answer.date,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
